{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序\n",
    "TF的设计哲学非常简洁，利用Python定义计算图，然后TF会高效执行，底层代码是C++。\n",
    "\n",
    "本章的主要内容有：\n",
    "\n",
    "- 安装\n",
    "- 创建第一个图并通过会话运行\n",
    "- 管理图\n",
    "- 节点的生命周期\n",
    "- 使用TF实现线性回归\n",
    "- 实现梯度下降\n",
    "- 为算法填充数据\n",
    "- 保存模型\n",
    "- 可视化图和训练曲线\n",
    "- 命名空间\n",
    "- 模块化\n",
    "- 共享变量\n",
    "- 练习\n",
    "\n",
    "这部分牵涉到了很多我还一知半解的概念。好好做练习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T11:20:38.991297Z",
     "start_time": "2018-03-05T11:20:29.259131Z"
    }
   },
   "source": [
    "### 设定好交互环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.310099Z",
     "start_time": "2018-03-07T08:34:14.282573Z"
    }
   },
   "outputs": [],
   "source": [
    "# 同时支持py2,py3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 使得输出稳定\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# 画图配置\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "# 保存绘图结果\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\") # 将多个路径组合后返回\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建第一个图并通过会话运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.365093Z",
     "start_time": "2018-03-07T08:34:14.313846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph() # 先重置图\n",
    "\n",
    "x = tf.Variable(3,name='x') # 给变量起名字是好习惯\n",
    "y = tf.Variable(4,name='y')\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就是我们想要定义的第一个运算图了，值得注意的是，现在为止代码并不会运行得到什么结果，只是将其视作图的设计。创建图的步骤完成。变量还未初始化，需要专门的步骤，显式初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.374777Z",
     "start_time": "2018-03-07T08:34:14.367312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f # 此时还只是个图的组成部分，没有结果出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.407318Z",
     "start_time": "2018-03-07T08:34:14.377360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这种一个一个初始化的方式实际不常用。我们直接用全局初始化就完事了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.417393Z",
     "start_time": "2018-03-07T08:34:14.410325Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close() # 不用with块的话需要手动关闭，见下面的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.435730Z",
     "start_time": "2018-03-07T08:34:14.420110Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.445595Z",
     "start_time": "2018-03-07T08:34:14.437986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这个看起来很自然，但是隐含的知识点不强调的话可能就被忽略了。不用with块的话，用`sess.run..`，而在with块里不是，而是调用变量的初始器，好像没用会话，实则代码的含义是：`tf.get_default_session().run(x.initializer)`。并且，`f.eval`也等同于`tf.get_default_session().run(f)`。`with`块已经把我们定义的会话作为默认会话了。 这大大提高了代码的可读性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.468980Z",
     "start_time": "2018-03-07T08:34:14.449280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 全局初始化\n",
    "init = tf.global_variables_initializer() # init节点\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.481440Z",
     "start_time": "2018-03-07T08:34:14.472465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 管理图\n",
    "\n",
    "任何创造的节点都会自动被加入默认图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.500931Z",
     "start_time": "2018-03-07T08:34:14.484865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph() # 判断是不是默认图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只用默认图在大部分场景下是合适的，但是有些场景下需要多个图时，我们也可以自己手动创建图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.517076Z",
     "start_time": "2018-03-07T08:34:14.503911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default(): # 将自己设定的图设置为默认用的图，但并不是取代默认的那个图\n",
    "    x2 = tf.Variable(2)\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.526376Z",
     "start_time": "2018-03-07T08:34:14.520152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph() # 自己设置的图和默认的图不是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 节点值的生命周期\n",
    "\n",
    "变量的生命开始的标志是：初始化被run起来\n",
    "变量的声明结束的标志是：session关闭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.555272Z",
     "start_time": "2018-03-07T08:34:14.530339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里虽然y,z同样依赖w,x，但是计算y时依赖的w,x计算出来后，z不会复用。除非代码按照下面的方式写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.572257Z",
     "start_time": "2018-03-07T08:34:14.558531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TF实现线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.872733Z",
     "start_time": "2018-03-07T08:34:14.575281Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)),housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.946206Z",
     "start_time": "2018-03-07T08:34:14.875828Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias,dtype=tf.float32,name='X')\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "with tf.Session() as sess:\n",
    "    theta_val = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.957316Z",
     "start_time": "2018-03-07T08:34:14.948910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.69535103e+01],\n",
       "       [  4.36627001e-01],\n",
       "       [  9.43351071e-03],\n",
       "       [ -1.07151151e-01],\n",
       "       [  6.44667268e-01],\n",
       "       [ -3.95081770e-06],\n",
       "       [ -3.78605886e-03],\n",
       "       [ -4.21335578e-01],\n",
       "       [ -4.34634268e-01]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现梯度下降\n",
    "\n",
    "第一种先用手动计算梯度的方式，然后调包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.973680Z",
     "start_time": "2018-03-07T08:34:14.960355Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 特征向量必须是归一化的\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m,1)),scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:14.987255Z",
     "start_time": "2018-03-07T08:34:14.976264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   6.60969987e-17   5.50808322e-18   6.60969987e-17\n",
      "  -1.06030602e-16  -1.10161664e-17   3.44255201e-18  -1.07958431e-15\n",
      "  -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ..., -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.111111111111\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:15.560930Z",
     "start_time": "2018-03-07T08:34:14.990454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  9.16154\n",
      "Epoch 100 MSE =  0.714501\n",
      "Epoch 200 MSE =  0.566705\n",
      "Epoch 300 MSE =  0.555572\n",
      "Epoch 400 MSE =  0.548811\n",
      "Epoch 500 MSE =  0.543636\n",
      "Epoch 600 MSE =  0.539629\n",
      "Epoch 700 MSE =  0.536509\n",
      "Epoch 800 MSE =  0.534068\n",
      "Epoch 900 MSE =  0.532147\n"
     ]
    }
   ],
   "source": [
    "# 手动计算梯度\n",
    "reset_graph()\n",
    "n_epoches = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name='X')\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name='y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name='theta')\n",
    "y_pred = tf.matmul(X,theta,name='predictions')\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X),error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoches):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch',epoch, 'MSE = ', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:15.571149Z",
     "start_time": "2018-03-07T08:34:15.563345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855226],\n",
       "       [ 0.88740271],\n",
       "       [ 0.14401656],\n",
       "       [-0.34770885],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.66145283],\n",
       "       [-0.63752782]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:15.580652Z",
     "start_time": "2018-03-07T08:34:15.573805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存和重用模型\n",
    "\n",
    "一旦训练好模型，就应该保存起来。保存起来的模型可以用在其他的项目中，也可以与其他的模型进行比较等。更重要的原因是，一旦电脑崩溃，可以用最近保存的那个checkpoint，而不用从头开始训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T11:38:05.782632Z",
     "start_time": "2018-03-07T11:38:03.885520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 9.16154\n",
      "Epoch 100 MSE= 0.714501\n",
      "Epoch 200 MSE= 0.566705\n",
      "Epoch 300 MSE= 0.555572\n",
      "Epoch 400 MSE= 0.548811\n",
      "Epoch 500 MSE= 0.543636\n",
      "Epoch 600 MSE= 0.539629\n",
      "Epoch 700 MSE= 0.536509\n",
      "Epoch 800 MSE= 0.534068\n",
      "Epoch 900 MSE= 0.532147\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epoches = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 数据准备\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32,name='X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1,1],-1.0, 1.0,seed=42),name='theta') # 生成随机数，注意n+1,1是theta的形状\n",
    "y_pred = tf.matmul(X,theta, name='predictions')\n",
    "error = y_pred - y # error是个向量\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse') # 得到一个标量的表达式\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "# 初始化节点\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 保存训练过程的工具\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoches):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch',epoch, 'MSE=',mse.eval())\n",
    "            save_path = saver.save(sess, '/tmp/my_model.ckpt')\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess,'/tmp/my_model_final.ckpt') # 最后存储一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T11:40:09.120534Z",
     "start_time": "2018-03-07T11:40:09.112679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249],\n",
       "       [ 0.88740271],\n",
       "       [ 0.14401659],\n",
       "       [-0.34770876],\n",
       "       [ 0.36178362],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.66145277],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面这部分插入的是`tf.reduce_mean`函数的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:46:08.447550Z",
     "start_time": "2018-03-07T08:46:08.431945Z"
    }
   },
   "outputs": [],
   "source": [
    "# 下面这部分插入的是`tf.reduce_mean`函数的使用\n",
    "a = [[1.,2.,3.,4.],[5.,6.,7.,8.]] # 一维很好理解，这里用的是二维\n",
    "re = tf.reduce_mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:46:09.828812Z",
     "start_time": "2018-03-07T08:46:09.808322Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    res = re.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:46:11.005427Z",
     "start_time": "2018-03-07T08:46:10.997784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型就一行代码即可，**restore**模型也同样简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T11:43:24.624443Z",
     "start_time": "2018-03-07T11:43:24.580585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'/tmp/my_model_final.ckpt')\n",
    "    best_theta_restored = theta.eval()\n",
    "    '/tmp/my_model.ckpt.data-00000-of-00001'\n",
    "    '/tmp/my_model.ckpt.index'\n",
    "    '/tmp/my_model.ckpt.meta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到我们在保存的时候，文件名是以`.ckpt`结尾，实际存储时，会保存为:\n",
    "\n",
    "<pre>\n",
    "'/tmp/my_model.ckpt.data-00000-of-00001'\n",
    "'/tmp/my_model.ckpt.index'\n",
    "'/tmp/my_model.ckpt.meta'\n",
    "</pre>\n",
    "\n",
    "我记得自己在第一次导入的时候看到这三个文件很懵，不知道怎么办，后来发现还是只需要导入以`.ckpt`结尾的文件即可。就像上面的做法一样。\n",
    "\n",
    "而不管是save还是restore，都是通过`saver = tf.train.Saver()`这个对象来实现的。\n",
    "\n",
    "另外，保存或者重新载入模型都是针对当前会话下所有的变量的，如果需要更加精细化的控制的话，也是可以做到的。下面举例子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T11:59:40.042321Z",
     "start_time": "2018-03-07T11:59:40.032875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta,best_theta_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:00:22.127035Z",
     "start_time": "2018-03-07T12:00:22.107332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({'weights': theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:01:29.918009Z",
     "start_time": "2018-03-07T12:01:29.910665Z"
    }
   },
   "source": [
    "上面这个只保存了名叫`weights`的theta变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，saver也会保存图结构本身，文件结尾是.meta。能够通过tf.train.import_meta_graph()载入图结构，返回一个saver，通过这个返回的saver能够重载图状态：变量的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:12:07.279003Z",
     "start_time": "2018-03-07T12:12:07.098210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph('/tmp/my_model_final.ckpt.meta') # 导入图结构\n",
    "theta = tf.get_default_graph().get_tensor_by_name('theta:0')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '/tmp/my_model_final.ckpt') # 载入图状态\n",
    "    best_theta_restored = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:12:41.724420Z",
     "start_time": "2018-03-07T12:12:41.717110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta,best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:14:22.673276Z",
     "start_time": "2018-03-07T12:14:22.664732Z"
    }
   },
   "source": [
    "这种可重载模型的方法使得我们能够重用预训练模型，且不用对应的Python代码去重建图。因为图本身也可以导入。通过.meta文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化图与训练过程 - 基于TensorBoard\n",
    "\n",
    "到目前为止，我们都是用`print`函数来监视训练过程。实际上有更好的方法，这个方法就是用Tensorboard。\n",
    "\n",
    "这种可视化的方法能够极大帮助我们识别图中的错误，发现瓶颈等。\n",
    "\n",
    "在Jupyter内也可显示，但是并不推荐，性能会很差，在浏览器中会更好一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:39:37.436818Z",
     "start_time": "2018-03-07T12:39:37.431239Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir = '/tmp/tf_logs' \n",
    "logdir = '{}/run-{}/'.format(root_logdir,now) # 将时间戳添加到保存的日志文件上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:39:38.735012Z",
     "start_time": "2018-03-07T12:39:38.618019Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoches = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(tf.float32,shape=(None,1), name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1,1], -1.0, 1.0, seed=42), name='theta') # 初始化theta\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y # 向量\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse') # 有负数的样本，用二次方\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:39:41.405644Z",
     "start_time": "2018-03-07T12:39:41.294303Z"
    }
   },
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE',mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph()) # 通过FileWriter来写入总结文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:39:42.550398Z",
     "start_time": "2018-03-07T12:39:42.545884Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoches = 10 # 控制训练轮次\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:39:45.162736Z",
     "start_time": "2018-03-07T12:39:43.746376Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1,1)[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # 运行初始化\n",
    "    \n",
    "    for epoch in range(n_epoches):\n",
    "        for batch_index in range(n_batches): # 整个样本被分为好几个batch\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index,batch_size)\n",
    "            \n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:39:46.203877Z",
     "start_time": "2018-03-07T12:39:46.197500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 注意要关闭FileWriter\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T12:38:22.648622Z",
     "start_time": "2018-03-07T12:38:22.641483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.07033372],\n",
       "       [ 0.86371452],\n",
       "       [ 0.12255152],\n",
       "       [-0.31211886],\n",
       "       [ 0.38510385],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376884],\n",
       "       [-0.803047  ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命名空间\n",
    "### 模块化\n",
    "\n",
    "这两个暂时不展开，先看下面这个主题。\n",
    "\n",
    "### 共享变量\n",
    "\n",
    "如果想在图中的各个组件共用某个变量的值，简单的方法是先定义一个变量，然后作为参数传值即可。对于少量的共享参数这个是可行的，一旦变量多起来后，就会很痛苦了。\n",
    "\n",
    "另外一种解决痛苦的方式是定义一个字典，或者定义一个类专门用来存储共享的变量。\n",
    "\n",
    "还有一种方式是将变量赋值为函数的属性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T13:01:51.496768Z",
     "start_time": "2018-03-07T13:01:51.487079Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 属性法\n",
    "def relu(X):\n",
    "    with tf.name_scope('relu'):\n",
    "        if not hasattr(relu,'threshold'):\n",
    "            relu.threshold = tf.Variable(0.0,name='threshold')\n",
    "        #[...]\n",
    "        return tf.maximum(z,relu.threshold, name='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow提供的方法\n",
    "\n",
    "TF提供了额外的选择，使得代码更加整洁与模块化。\n",
    "\n",
    "方法就是通过`get_variable`函数来创建共享变量。如果变量还不存在的话，否则重用现在的即可。具体行为通过`variable_scope`属性控制。\n",
    "\n",
    "下面的代码就会创建'relu/threshold'变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T13:04:03.537457Z",
     "start_time": "2018-03-07T13:04:03.521466Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope('relu'):\n",
    "    threshold = tf.get_variable('threshold',shape=(),initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是上面这种写法，如果前面已经存在了，就会出现错误。需要显式设定`reuse`为True,此时就不必再指定变量的shape和初始器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T13:09:20.723317Z",
     "start_time": "2018-03-07T13:09:20.701631Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable relu/threshold does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-9ffe207f4e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1205\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    758\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[1;32m    759\u001b[0m                        \u001b[0;34m\"tf.get_variable(). Did you mean to set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                        \"reuse=tf.AUTO_REUSE in VarScope?\" % name)\n\u001b[0m\u001b[1;32m    761\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n",
      "\u001b[0;31mValueError\u001b[0m: Variable relu/threshold does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope('relu',reuse=True):\n",
    "    threshold = tf.get_variable('threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行上面的cell，发现出现错误就是因为没有定义过这个变量。与上面效果相同的方法是下面这种，调用`scope_reuse_variables()`来指定reuse属性为真。意味着也会有与上面相同的错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T13:27:18.461578Z",
     "start_time": "2018-03-07T13:27:18.448793Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这个执行起来会出现和上面一样的错\n",
    "with tf.variable_scope('relu') as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable('threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
